{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59656cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from network.mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d1b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#######    CHANGE PARAMETERS HERE    ########\n",
    "#############################################\n",
    "# number of trajectories stitched together\n",
    "n_trajs = 20    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b41f62",
   "metadata": {},
   "source": [
    "## Prepare Data and Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257c387",
   "metadata": {},
   "source": [
    "### Load traj data and Visualise the data trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbb0376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([1005000, 128])\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "trajs = np.load('all_traj.npy')\n",
    "trajs = torch.tensor(trajs).to(device).reshape(-1, trajs.shape[-1]*trajs.shape[-2])\n",
    "print('Data shape:', trajs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21134c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the data trajectories\n",
    "for i in range(0, trajs.shape[0], 2000):\n",
    "    traj = trajs[i].reshape(-1, 2)\n",
    "    plt.scatter(traj[:, 0].cpu(), traj[:, 1].cpu(), s=1, c='k', alpha=0.5)\n",
    "\n",
    "dim = trajs.shape[-1]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a145700",
   "metadata": {},
   "source": [
    "### Load Pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_net = MLP(dim, device, data_sigma=0.6, num_layers=5, num_hid=512).to(device)\n",
    "ema_net.load_state_dict(torch.load(\"traj_net.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13472ee",
   "metadata": {},
   "source": [
    "## Prepare task info, Define Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea6a51",
   "metadata": {},
   "source": [
    "### Define task info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2332a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([-0.95, 0.95]).to(device)\n",
    "B = torch.tensor([0.95, -0.95]).to(device)\n",
    "path_length = 64  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2a2bb",
   "metadata": {},
   "source": [
    "### Define reward functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12acf6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define internediate rewards for PT control\n",
    "def intermediate_reward1(x0_hat, n_trajs):\n",
    "    ### reward to ensure the continuity of the trajectory\n",
    "    x0_hat = x0_hat.reshape(-1, n_trajs, path_length, 2)\n",
    "    x_next_start = x0_hat[:, 1:, 0, :]\n",
    "    x_last_end = x0_hat[:, :-1, -1, :]\n",
    "    c = 1e-5\n",
    "    d2 = (x_next_start - x_last_end)**2 + c\n",
    "    \n",
    "    r = -(d2 +  10 * d2**0.5).sum(-1) * 100\n",
    "    r = r.sum(-1) \n",
    "    return r\n",
    "\n",
    "def intermediate_reward2(x0_hat, n_trajs):\n",
    "    ### reward to ensure the trajectory starts and ends at the correct points\n",
    "    x0_hat = x0_hat.reshape(-1, n_trajs, path_length, 2)\n",
    "    x_first_start = x0_hat[:, 0, 0, :]\n",
    "    x_last_end = x0_hat[:, -1, -1, :]\n",
    "    c = 1e-5\n",
    "    d21 = (x_first_start - A)**2 + c\n",
    "    r = -(d21 + 10*d21**0.5).sum(-1) * 100 *  n_trajs\n",
    "    d22 = (x_last_end - B)**2 + c\n",
    "    r += -(d22 + 10*d22**0.5).sum(-1) * 100 * n_trajs\n",
    "    return r\n",
    "\n",
    "def intermediate_reward3(x0_hat, n_trajs):\n",
    "    ### reward to ensure the trajectory does not go too far away from the original trajectory\n",
    "    x0_hat = x0_hat.reshape(-1, n_trajs * path_length * 2)\n",
    "    r =  (x0_hat.abs() > 5.0).any(-1).float() * -1e10\n",
    "    return r\n",
    "\n",
    "def reward(xt, n_trajs):\n",
    "    r1 = intermediate_reward1(xt, n_trajs)\n",
    "    r2 = intermediate_reward2(xt, n_trajs)\n",
    "    r3 = intermediate_reward3(xt, n_trajs)\n",
    "    return  r3 + r2 + r1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d4d7eb",
   "metadata": {},
   "source": [
    "### Define Denoising Schedule and Reward Coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a431cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDM denoising schedule\n",
    "\n",
    "tmax = 20\n",
    "tmin = 1e-3\n",
    "rho = 7\n",
    "steps = 601\n",
    "\n",
    "ts = tmin ** (1/rho) + np.arange(steps)/(steps-1) * (tmax ** (1/rho) - tmin ** (1/rho))\n",
    "ts = ts ** rho\n",
    "\n",
    "\n",
    "\n",
    "# define reward coef \n",
    "# This coefficient is used to scale the reward at different time steps\n",
    "# to ensure the reward at the early time steps is close to 0\n",
    "# and the reward at the later time steps is close to the final reward defined above\n",
    "coef = np.geomspace(1e-4, 1, steps)[::-1]\n",
    "\n",
    "coef_min = 1e-10\n",
    "coef_max = 1\n",
    "rho = 10\n",
    "coef = coef_min ** (1/rho) + np.linspace(0, 1, steps)[::-1] * (coef_max ** (1/rho) - coef_min ** (1/rho) )\n",
    "coef = coef ** rho\n",
    "plt.plot(coef, label='Reward Coef')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd30285",
   "metadata": {},
   "source": [
    "## CREPE Control Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865b1b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Log Density\n",
    "def log_norm_prob(x, mu, std):\n",
    "    # expand std to match x shape\n",
    "    std = std.expand(x.shape)\n",
    "    return -0.5 * ((x - mu) / std).pow(2).sum(-1) - (std.log() + np.log(2*np.pi)/2).sum(-1)\n",
    "def EM_solve_guidance(model, start_samples, n_trajs, all_levels):\n",
    "    Rs = []\n",
    "    with torch.no_grad():\n",
    "        samples = start_samples\n",
    "        Samples = [(ts[-1], len(ts)-1, start_samples.detach().cpu())]\n",
    "        for i in tqdm(range(ts.shape[0]-1, 0, -1)):\n",
    "            t = torch.ones(samples.shape[0], 1).to(samples.device) * ts[i]\n",
    "            t_1 = torch.ones(samples.shape[0], 1).to(samples.device) * ts[i-1]\n",
    "\n",
    "            Delta_t = (t - t_1).abs()\n",
    "            x_hat = model(samples, t.flatten()) \n",
    "            std = torch.sqrt(2*Delta_t*t)\n",
    "            score = - (samples - x_hat) / t ** 2 \n",
    "\n",
    "            with torch.enable_grad():\n",
    "                samples.requires_grad_()\n",
    "                x0_hat = model(samples, t.flatten())\n",
    "                r = reward(x0_hat, n_trajs).sum() * coef[i]\n",
    "                guidance = torch.clip(torch.autograd.grad(r, samples)[0], -100, 100)\n",
    "                samples = samples.detach()\n",
    "                Rs.append(r.item())\n",
    "            score = score + guidance\n",
    "\n",
    "            dx = score * 2 * t * Delta_t  + std * torch.randn_like(samples)\n",
    "\n",
    "            samples_new = samples + dx\n",
    "            if i-1 in all_levels:\n",
    "                Samples.append((ts[i-1], i-1, samples_new.detach().cpu()))\n",
    "\n",
    "            samples = samples_new\n",
    "\n",
    "        return Samples, Rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all time steps as PT levels\n",
    "gap = 1\n",
    "assert (steps-1) % gap == 0, \"Steps must be divisible by gap + 1\"\n",
    "all_levels = np.linspace(0, steps-1, (steps-1)//gap + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d97c26",
   "metadata": {},
   "source": [
    "### Run Initial Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "45adf427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:02<00:00, 263.77it/s]\n"
     ]
    }
   ],
   "source": [
    "bsz = 1\n",
    "start_samples = torch.randn(bsz*n_trajs, dim, device=device) * ts[-1]\n",
    "Samples, Rs = EM_solve_guidance(ema_net, start_samples, n_trajs, all_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8242d1ea",
   "metadata": {},
   "source": [
    "### Define the step size for local move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bafd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's define the step size for local move\n",
    "idx = np.arange(steps)[::-1]\n",
    "Delta_t = (ts[np.clip(idx+1, 0, len(ts)-1)] - ts[idx])\n",
    "Delta_t[0] = Delta_t[1]  # first step is always the same\n",
    "step_size = Delta_t*ts[::-1]\n",
    "step_size = step_size[::-1]\n",
    "plt.plot(step_size)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ee232",
   "metadata": {},
   "source": [
    "### Run PT starting from the initial sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8950c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def APT_control(n_trajs, path_length, model_traj, Samples, step_size, gap):\n",
    "    # we run two steps of APT\n",
    "    # in the first step, we only exchange the samples at even indices\n",
    "    # in the second step, we exchange the samples at odd indices\n",
    "    time_steps = torch.from_numpy(np.array([s[0] for s in Samples])).to(device).float()\n",
    "    samples = torch.stack([s[2] for s in Samples], dim=0).to(device).clone() # (time_steps, n_trajs, path_length*2)\n",
    "    idx = np.array([s[1] for s in Samples])\n",
    "\n",
    "    step_size = torch.from_numpy(step_size[idx]).float().to(samples.device)\n",
    "    coef_all = torch.from_numpy(coef[idx]).float().to(samples.device)\n",
    "\n",
    "    ALL_SAMPLES = []\n",
    "    start_idx = 0\n",
    "    MASKS1 = []\n",
    "    MASKS2 = []\n",
    "    NEW_SAMPLES = []\n",
    "    for start_idx in [0, 1]:\n",
    "        with torch.no_grad():\n",
    "            # local move \n",
    "            local_move_time_steps = time_steps.reshape(-1, 1, 1).expand(-1, n_trajs, 1)\n",
    "            with torch.enable_grad():\n",
    "                samples = samples.clone().requires_grad_()\n",
    "                x_hat = model_traj(samples.reshape(-1, samples.shape[-1]), local_move_time_steps.flatten()).reshape(samples.shape)\n",
    "                guide = torch.clip(torch.autograd.grad(outputs=(reward(x_hat, n_trajs).flatten()*coef_all.flatten()).sum(), inputs=samples)[0], -1000, 1000)\n",
    "            samples = samples.detach()\n",
    "            score = - (samples - x_hat) / local_move_time_steps ** 2\n",
    "            score = score.detach()\n",
    "            guided_score = score + guide\n",
    "\n",
    "            if guided_score.isnan().any():\n",
    "                print('NaN detected in score, skipping step')\n",
    "                continue\n",
    "            dx = guided_score * step_size.reshape(-1, 1, 1)  + (step_size.reshape(-1, 1, 1)*2)**0.5 * torch.randn_like(samples)\n",
    "            samples = samples + dx\n",
    "\n",
    "            # # replace the first sample with the start sample\n",
    "            samples[0] = torch.randn(samples[0].shape, device=device) * ts[-1]\n",
    "\n",
    "            # swap\n",
    "            x1 = samples[start_idx:-1:2]\n",
    "            x0 = samples[start_idx+1::2]\n",
    "            idx_1 = idx[start_idx:-1:2]\n",
    "            idx_0 = idx[start_idx+1::2]\n",
    "\n",
    "            w = 0\n",
    "\n",
    " \n",
    "            # x1 to x0\n",
    "            for step in range(gap):\n",
    "                t_cur = torch.from_numpy(ts[idx_1 - step].reshape(-1, 1, 1)).float().to(x1.device).expand(-1, n_trajs, 1)\n",
    "                t_next = torch.from_numpy(ts[idx_1 - 1 - step].reshape(-1, 1, 1)).float().to(x1.device).expand(-1, n_trajs, 1)\n",
    "\n",
    "                coef_cur = torch.from_numpy(coef[idx_1 - step]).float().to(x1.device)\n",
    "                coef_next = torch.from_numpy(coef[idx_1 - 1 - step]).float().to(x1.device)\n",
    "                assert coef_cur.shape == (t_cur.shape[0], )\n",
    "                assert coef_next.shape == (t_next.shape[0], )\n",
    "\n",
    "\n",
    "\n",
    "                Delta_t = (t_cur - t_next).abs()\n",
    "\n",
    "                x_hat = model_traj(x1.reshape(-1, x1.shape[-1]), t_cur.flatten()).reshape(-1, n_trajs, x1.shape[-1])\n",
    "                std = torch.sqrt(2*Delta_t*t_cur)\n",
    "                score = - (x1 - x_hat) / t_cur ** 2 \n",
    "\n",
    "                with torch.enable_grad():\n",
    "                    x1.requires_grad_()\n",
    "                    x0_hat = model_traj(x1.reshape(-1, x1.shape[-1]), t_cur.flatten()).reshape(-1, n_trajs, x1.shape[-1])\n",
    "                    r = reward(x0_hat, n_trajs) * coef_cur\n",
    "                    # print(r.shape)\n",
    "                    guidance = torch.clip(torch.autograd.grad(r.sum(), x1)[0], -1000, 1000)\n",
    "                    x1 = x1.detach()\n",
    "                guided_score = score + guidance\n",
    "\n",
    "\n",
    "                dx = guided_score * 2 * t_cur * Delta_t + std * torch.randn_like(x1)\n",
    "                x0_candidate = x1 + dx\n",
    "\n",
    "\n",
    "\n",
    "                # diffusion forward process\n",
    "                fwd_mean = x0_candidate\n",
    "                fwd_std = torch.sqrt(2*Delta_t*t_next)\n",
    "                dm_fwd = log_norm_prob(x1, fwd_mean, fwd_std).sum(-1) # (time_steps, )\n",
    "\n",
    "                # diffusion backward process\n",
    "                bwd_mean = x1 + score * 2 * t_cur * Delta_t\n",
    "                bwd_std = torch.sqrt(2*Delta_t*t_cur)\n",
    "                dm_bwd = log_norm_prob(x0_candidate, bwd_mean, bwd_std).sum(-1) # (time_steps, )\n",
    "\n",
    "\n",
    "                # sampling forward process\n",
    "                fwd_mean = x0_candidate  \n",
    "                fwd_std = torch.sqrt(2*Delta_t*t_next)\n",
    "                sample_fwd = log_norm_prob(x1, fwd_mean, fwd_std).sum(-1) # (time_steps, )\n",
    "\n",
    "                # sampling backward process\n",
    "                bwd_mean = x1 + guided_score * 2 * t_cur * Delta_t\n",
    "                bwd_std = torch.sqrt(2*Delta_t*t_cur)\n",
    "                sample_bwd = log_norm_prob(x0_candidate, bwd_mean, bwd_std).sum(-1) # (time_steps, )\n",
    "\n",
    "\n",
    "                assert sample_bwd.shape == (x1.shape[0] ,)\n",
    "\n",
    "                # calculate intermediate reward\n",
    "                x0_candidate_x0_hat = model_traj(x0_candidate.reshape(-1, x0_candidate.shape[-1]), t_next.flatten()).reshape(-1, n_trajs, x0_candidate.shape[-1])\n",
    "                r_x0_candidate = reward(x0_candidate_x0_hat, n_trajs) * coef_next\n",
    "\n",
    "                x1_x0_hat = model_traj(x1.reshape(-1, x1.shape[-1]), t_cur.flatten()).reshape(-1, n_trajs, x1.shape[-1])\n",
    "                r_x1 = reward(x1_x0_hat, n_trajs) * coef_cur\n",
    "\n",
    "                assert r_x0_candidate.ndim == 1\n",
    "                assert r_x1.ndim == 1\n",
    "\n",
    "                w += (sample_fwd - sample_bwd) + (dm_bwd - dm_fwd) + (r_x0_candidate - r_x1) \n",
    "                \n",
    "\n",
    "            # x0 to x1\n",
    "            for step in range(gap):\n",
    "                t_cur = torch.from_numpy(ts[idx_0 + step].reshape(-1, 1, 1)).float().to(x0.device).expand(-1, n_trajs, 1)\n",
    "                t_next = torch.from_numpy(ts[idx_0 + 1 + step].reshape(-1, 1, 1)).float().to(x0.device).expand(-1, n_trajs, 1)\n",
    "                coef_cur = torch.from_numpy(coef[idx_0 + step]).float().to(x0.device)\n",
    "                coef_next = torch.from_numpy(coef[idx_0 + 1 + step]).float().to(x0.device)\n",
    "                assert coef_cur.shape == (t_cur.shape[0], )\n",
    "                assert coef_next.shape == (t_next.shape[0], )\n",
    "\n",
    "\n",
    "                Delta_t = (t_cur - t_next).abs()\n",
    "\n",
    "                std = torch.sqrt(2*Delta_t*t_cur)\n",
    "                dx = std * torch.randn_like(x0)\n",
    "                x1_candidate = x0 + dx\n",
    "\n",
    "\n",
    "\n",
    "                # diffusion forward process\n",
    "                fwd_mean = x0\n",
    "                fwd_std = torch.sqrt(2*Delta_t*t_cur)\n",
    "                dm_fwd = log_norm_prob(x1_candidate, fwd_mean, fwd_std).sum(-1)\n",
    "\n",
    "                # diffusion backward process\n",
    "                x_hat = model_traj(x1_candidate.reshape(-1, x1_candidate.shape[-1]), t_next.flatten()).reshape(-1, n_trajs, x1_candidate.shape[-1])\n",
    "                score = - (x1_candidate - x_hat) / t_next ** 2 \n",
    "                bwd_mean = x1_candidate + score * 2 * t_next * Delta_t\n",
    "                bwd_std = torch.sqrt(2*Delta_t*t_next)\n",
    "                dm_bwd = log_norm_prob(x0, bwd_mean, bwd_std).sum(-1)\n",
    "\n",
    "\n",
    "                # sampling forward process\n",
    "                fwd_mean = x0 \n",
    "                fwd_std = torch.sqrt(2*Delta_t*t_cur)\n",
    "                sample_fwd = log_norm_prob(x1_candidate, fwd_mean, fwd_std).sum(-1)\n",
    "\n",
    "                # sampling backward process\n",
    "\n",
    "                with torch.enable_grad():\n",
    "                    x1_candidate.requires_grad_()\n",
    "                    x0_hat = model_traj(x1_candidate.reshape(-1, x1_candidate.shape[-1]), t_next.flatten()).reshape(-1, n_trajs, x1_candidate.shape[-1])\n",
    "                    r = reward(x0_hat, n_trajs) * coef_next\n",
    "                    guidance = torch.clip(torch.autograd.grad(r.sum(), x1_candidate)[0], -100, 100)\n",
    "                    x1_candidate = x1_candidate.detach()\n",
    "                guided_score = score + guidance\n",
    "\n",
    "                bwd_mean = x1_candidate + guided_score * 2 * t_next * Delta_t\n",
    "                bwd_std = torch.sqrt(2*Delta_t*t_next)\n",
    "                sample_bwd = log_norm_prob(x0, bwd_mean, bwd_std).sum(-1)\n",
    "\n",
    "\n",
    "                # calculate intermediate reward\n",
    "                x1_candidate_x0_hat = model_traj(x1_candidate.reshape(-1, x1_candidate.shape[-1]), t_next.flatten()).reshape(-1, n_trajs, x1_candidate.shape[-1])\n",
    "                r_x1_candidate = reward(x1_candidate_x0_hat, n_trajs) * coef_next\n",
    "\n",
    "                x0_x0_hat = model_traj(x0.reshape(-1, x0.shape[-1]), t_cur.flatten()).reshape(-1, n_trajs, x0.shape[-1])\n",
    "                r_x0 = reward(x0_x0_hat, n_trajs) * coef_cur\n",
    "\n",
    "                assert r_x1_candidate.ndim == 1\n",
    "                assert r_x0.ndim == 1\n",
    "\n",
    "                w -= ((sample_fwd - sample_bwd) + (dm_bwd - dm_fwd)  + (r_x0 - r_x1_candidate))\n",
    "                \n",
    "            u = torch.rand_like(w).log()\n",
    "            mask = (u < w).reshape(-1, 1, 1)\n",
    "            mask[-1] = 1 # change the last time step mask, to ensure the last time step is always accepted (this will not affect the result as the last time step has little effect on the final result)\n",
    "            if start_idx == 0:\n",
    "                MASKS2.append(mask.reshape(-1))\n",
    "            else:\n",
    "                MASKS1.append(mask.reshape(-1))\n",
    "\n",
    "\n",
    "            samples[start_idx:-1:2] = torch.where(mask, x1_candidate, x1)\n",
    "            samples[start_idx+1::2] = torch.where(mask, x0_candidate, x0)\n",
    "            ALL_SAMPLES.append(samples.detach().cpu())\n",
    "\n",
    "\n",
    "    for i in range(len(ALL_SAMPLES[-1])):\n",
    "        NEW_SAMPLES.append(\n",
    "            (time_steps[i].item(), idx[i].item(), ALL_SAMPLES[-1][i][None].reshape(n_trajs, dim))\n",
    "        )    \n",
    "    return ALL_SAMPLES, MASKS1, MASKS2, NEW_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7b33e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_SAMPLES = []\n",
    "MASK1 = []\n",
    "MASK2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in tqdm(range(50000)): # 150000 PT iterations\n",
    "    with torch.no_grad():\n",
    "        all_samples, MASKS1, MASKS2, NEW_SAMPLES = APT_control(n_trajs, \n",
    "                                                               path_length,\n",
    "                                                               model_traj=ema_net,\n",
    "                                                               Samples=Samples, \n",
    "                                                               step_size=step_size, \n",
    "                                                               gap=gap)\n",
    "        if iter % 200 == 0: # save the samples and masks every 200 iterations\n",
    "            ALL_SAMPLES += all_samples\n",
    "            MASK1 += MASKS1\n",
    "            MASK2 += MASKS2\n",
    "        Samples = NEW_SAMPLES\n",
    "\n",
    "        if iter % 5000 == 0:\n",
    "            plt.figure(figsize=(10, 3.5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            x = trajs[torch.randint(0, trajs.shape[0], (500,))].reshape(-1, 64, 2)\n",
    "            for i in range(x.shape[0]):\n",
    "                plt.plot(x[i, :, 0].cpu().detach(), x[i, :, 1].cpu().detach(), color='black' , alpha=0.05, linewidth=1)\n",
    "            # plot A and \n",
    "            plt.scatter(A[0].cpu(), A[1].cpu(), s=100, c='r')\n",
    "            plt.scatter(B[0].cpu(), B[1].cpu(), s=100, c='b')\n",
    "\n",
    "\n",
    "            s = Samples[-1][-1].reshape(-1, n_trajs, path_length, 2)[0]\n",
    "            \n",
    "            # Create colormap from yellow to red\n",
    "            from matplotlib.colors import LinearSegmentedColormap\n",
    "            cmap = LinearSegmentedColormap.from_list(\"yellow_red\", [\"yellow\", \"red\"])\n",
    "            cmap = LinearSegmentedColormap.from_list(\n",
    "                \"blue_green_orange\",\n",
    "                [\"#0151AD\", \"#00CC6DB3\", \"#FFB108\", \"#FF0000CF\"]  # bright blue → vivid green → warm orange\n",
    "            )\n",
    "            # Normalize for values 1–20\n",
    "            norm = plt.Normalize(vmin=1, vmax=n_trajs)\n",
    "            for i in range(s.shape[0]):\n",
    "                plt.plot(s[i, :, 0].cpu().detach(), s[i, :, 1].cpu().detach(), color=cmap(norm(i)), linewidth=3)\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(torch.stack(MASK1[-100:]).float().mean(0).cpu().numpy())\n",
    "            plt.plot(torch.stack(MASK2[-100:]).float().mean(0).cpu().numpy())\n",
    "            plt.show()\n",
    "\n",
    "            ALL_sub_samples = [i[::50] for i in ALL_SAMPLES] # thinned samples for saving memory\n",
    "            ALL_sub_samples = torch.stack(ALL_sub_samples)\n",
    "            # save ALL_SAMPLES (thinned)\n",
    "            torch.save(ALL_sub_samples, f'task_online.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685145d",
   "metadata": {},
   "source": [
    "## Add New Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c74b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([-0.95, 0.95]).to(device)\n",
    "B = torch.tensor([0.95, -0.95]).to(device)\n",
    "R = torch.tensor([0.2, -0.52]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0874b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def intermediate_reward4(x0_hat, n_trajs):\n",
    "    x0_hat = x0_hat.reshape(-1, n_trajs * path_length, 2)\n",
    "    c = 1e-5\n",
    "    d2 = ((x0_hat - R)**2) + c\n",
    "    d2 = d2 + 10*d2**0.5\n",
    "    d2 = d2.sum(-1) \n",
    "    attention = torch.softmax(-d2*10, dim=-1)\n",
    "    \n",
    "    d2 = (attention * d2).sum(-1)\n",
    "    r = -(d2) *  n_trajs * 100\n",
    "    return r\n",
    "\n",
    "def reward(xt, n_trajs):\n",
    "    r1 = intermediate_reward1(xt, n_trajs)\n",
    "    r2 = intermediate_reward2(xt, n_trajs)\n",
    "    r3 = intermediate_reward3(xt, n_trajs)\n",
    "    r4 = intermediate_reward4(xt, n_trajs)\n",
    "    return  r3 + r2 + r1 + r4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978fecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in tqdm(range(50000)): # 150000 PT iterations\n",
    "    with torch.no_grad():\n",
    "        all_samples, MASKS1, MASKS2, NEW_SAMPLES = APT_control(n_trajs, \n",
    "                                                               path_length,\n",
    "                                                               model_traj=ema_net,\n",
    "                                                               Samples=Samples, \n",
    "                                                               step_size=step_size, \n",
    "                                                               gap=gap)\n",
    "        if iter % 200 == 0: # save the samples and masks every 200 iterations\n",
    "            ALL_SAMPLES += all_samples\n",
    "            MASK1 += MASKS1\n",
    "            MASK2 += MASKS2\n",
    "        Samples = NEW_SAMPLES\n",
    "\n",
    "        if iter % 5000 == 0:\n",
    "            plt.figure(figsize=(10, 3.5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            x = trajs[torch.randint(0, trajs.shape[0], (500,))].reshape(-1, 64, 2)\n",
    "            for i in range(x.shape[0]):\n",
    "                plt.plot(x[i, :, 0].cpu().detach(), x[i, :, 1].cpu().detach(), color='black' , alpha=0.05, linewidth=1)\n",
    "            # plot A and \n",
    "            plt.scatter(A[0].cpu(), A[1].cpu(), s=100, c='r')\n",
    "            plt.scatter(B[0].cpu(), B[1].cpu(), s=100, c='b')\n",
    "\n",
    "\n",
    "            s = Samples[-1][-1].reshape(-1, n_trajs, path_length, 2)[0]\n",
    "            \n",
    "            # Create colormap from yellow to red\n",
    "            from matplotlib.colors import LinearSegmentedColormap\n",
    "            cmap = LinearSegmentedColormap.from_list(\"yellow_red\", [\"yellow\", \"red\"])\n",
    "            cmap = LinearSegmentedColormap.from_list(\n",
    "                \"blue_green_orange\",\n",
    "                [\"#0151AD\", \"#00CC6DB3\", \"#FFB108\", \"#FF0000CF\"]  # bright blue → vivid green → warm orange\n",
    "            )\n",
    "            # Normalize for values 1–20\n",
    "            norm = plt.Normalize(vmin=1, vmax=n_trajs)\n",
    "            for i in range(s.shape[0]):\n",
    "                plt.plot(s[i, :, 0].cpu().detach(), s[i, :, 1].cpu().detach(), color=cmap(norm(i)), linewidth=3)\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(torch.stack(MASK1[-100:]).float().mean(0).cpu().numpy())\n",
    "            plt.plot(torch.stack(MASK2[-100:]).float().mean(0).cpu().numpy())\n",
    "            plt.show()\n",
    "\n",
    "            ALL_sub_samples = [i[::50] for i in ALL_SAMPLES] # thinned samples for saving memory\n",
    "            ALL_sub_samples = torch.stack(ALL_sub_samples)\n",
    "            # save ALL_SAMPLES (thinned)\n",
    "            torch.save(ALL_sub_samples, f'task_online.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_sub_samples = [i[::50] for i in ALL_SAMPLES]\n",
    "ALL_sub_samples = torch.stack(ALL_sub_samples)\n",
    "# save ALL_SAMPLES\n",
    "torch.save(ALL_sub_samples, f'task_online.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FEP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
